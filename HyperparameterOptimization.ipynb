{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JoeyMucci/SemanticSegmentationSatelliteImagery/blob/main/HyperparameterOptimization.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install hpbandster # Hyperparameter Optimization\n",
        "import logging\n",
        "logging.basicConfig(level=logging.WARNING)\n",
        "import argparse\n",
        "import hpbandster.core.nameserver as hpns\n",
        "import hpbandster.core.result as hpres\n",
        "from hpbandster.optimizers import BOHB as BOHB\n",
        "from hpbandster.examples.commons import MyWorker\n",
        "import numpy as np\n",
        "import time\n",
        "import ConfigSpace as CS\n",
        "from hpbandster.core.worker import Worker\n",
        "\n",
        "import logging\n",
        "import os\n",
        "import cv2\n",
        "!pip install patchify \n",
        "!pip install segmentation-models \n",
        "import tensorflow\n",
        "from matplotlib import pyplot as plt\n",
        "from patchify import patchify\n",
        "from PIL import Image\n",
        "import segmentation_models as sm\n",
        "from tensorflow.keras.metrics import MeanIoU\n",
        "from keras.metrics.metrics import PrecisionAtRecall\n",
        "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
        "import sys\n",
        "path_m = '/content/drive/MyDrive/ColabNotebooks/'\n",
        "sys.path.insert(0,path_m)\n",
        "import simple_multi_unet_model\n",
        "from simple_multi_unet_model import multi_unet_model, jacard_coef  "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IKRGLg0al67U",
        "outputId": "15a39c63-dd7f-427d-d8ec-2ec2dc6fef62"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting hpbandster\n",
            "  Downloading hpbandster-0.7.4.tar.gz (51 kB)\n",
            "\u001b[K     |████████████████████████████████| 51 kB 114 kB/s \n",
            "\u001b[?25hCollecting Pyro4\n",
            "  Downloading Pyro4-4.82-py2.py3-none-any.whl (89 kB)\n",
            "\u001b[K     |████████████████████████████████| 89 kB 3.9 MB/s \n",
            "\u001b[?25hCollecting serpent\n",
            "  Downloading serpent-1.41-py3-none-any.whl (9.6 kB)\n",
            "Collecting ConfigSpace\n",
            "  Downloading ConfigSpace-0.6.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.9 MB 45.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from hpbandster) (1.21.6)\n",
            "Requirement already satisfied: statsmodels in /usr/local/lib/python3.7/dist-packages (from hpbandster) (0.12.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from hpbandster) (1.7.3)\n",
            "Collecting netifaces\n",
            "  Downloading netifaces-0.11.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (32 kB)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.7/dist-packages (from ConfigSpace->hpbandster) (3.0.9)\n",
            "Requirement already satisfied: cython in /usr/local/lib/python3.7/dist-packages (from ConfigSpace->hpbandster) (0.29.32)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from ConfigSpace->hpbandster) (4.1.1)\n",
            "Requirement already satisfied: patsy>=0.5 in /usr/local/lib/python3.7/dist-packages (from statsmodels->hpbandster) (0.5.3)\n",
            "Requirement already satisfied: pandas>=0.21 in /usr/local/lib/python3.7/dist-packages (from statsmodels->hpbandster) (1.3.5)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.21->statsmodels->hpbandster) (2022.6)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.21->statsmodels->hpbandster) (2.8.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from patsy>=0.5->statsmodels->hpbandster) (1.15.0)\n",
            "Building wheels for collected packages: hpbandster\n",
            "  Building wheel for hpbandster (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for hpbandster: filename=hpbandster-0.7.4-py3-none-any.whl size=80009 sha256=69f54e213e66bac12322f0178ab98337fc4ee3d5bfbf1369bfbba6cf2a55b1af\n",
            "  Stored in directory: /root/.cache/pip/wheels/d9/88/fc/61ab6b9f386a386839668631c39a6dc3c2fb0ec7000d552faa\n",
            "Successfully built hpbandster\n",
            "Installing collected packages: serpent, Pyro4, netifaces, ConfigSpace, hpbandster\n",
            "Successfully installed ConfigSpace-0.6.0 Pyro4-4.82 hpbandster-0.7.4 netifaces-0.11.0 serpent-1.41\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting patchify\n",
            "  Downloading patchify-0.2.3-py3-none-any.whl (6.6 kB)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.7/dist-packages (from patchify) (1.21.6)\n",
            "Installing collected packages: patchify\n",
            "Successfully installed patchify-0.2.3\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting segmentation-models\n",
            "  Downloading segmentation_models-1.0.1-py3-none-any.whl (33 kB)\n",
            "Collecting efficientnet==1.0.0\n",
            "  Downloading efficientnet-1.0.0-py3-none-any.whl (17 kB)\n",
            "Collecting keras-applications<=1.0.8,>=1.0.7\n",
            "  Downloading Keras_Applications-1.0.8-py3-none-any.whl (50 kB)\n",
            "\u001b[K     |████████████████████████████████| 50 kB 6.0 MB/s \n",
            "\u001b[?25hCollecting image-classifiers==1.0.0\n",
            "  Downloading image_classifiers-1.0.0-py3-none-any.whl (19 kB)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.7/dist-packages (from efficientnet==1.0.0->segmentation-models) (0.18.3)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.7/dist-packages (from keras-applications<=1.0.8,>=1.0.7->segmentation-models) (1.21.6)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras-applications<=1.0.8,>=1.0.7->segmentation-models) (3.1.0)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py->keras-applications<=1.0.8,>=1.0.7->segmentation-models) (1.5.2)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.7/dist-packages (from scikit-image->efficientnet==1.0.0->segmentation-models) (2021.11.2)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from scikit-image->efficientnet==1.0.0->segmentation-models) (1.3.0)\n",
            "Requirement already satisfied: scipy>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from scikit-image->efficientnet==1.0.0->segmentation-models) (1.7.3)\n",
            "Requirement already satisfied: matplotlib!=3.0.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image->efficientnet==1.0.0->segmentation-models) (3.2.2)\n",
            "Requirement already satisfied: pillow!=7.1.0,!=7.1.1,>=4.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image->efficientnet==1.0.0->segmentation-models) (7.1.2)\n",
            "Requirement already satisfied: imageio>=2.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image->efficientnet==1.0.0->segmentation-models) (2.9.0)\n",
            "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image->efficientnet==1.0.0->segmentation-models) (2.6.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet==1.0.0->segmentation-models) (0.11.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet==1.0.0->segmentation-models) (2.8.2)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet==1.0.0->segmentation-models) (3.0.9)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet==1.0.0->segmentation-models) (1.4.4)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.0.1->matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet==1.0.0->segmentation-models) (4.1.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet==1.0.0->segmentation-models) (1.15.0)\n",
            "Installing collected packages: keras-applications, image-classifiers, efficientnet, segmentation-models\n",
            "Successfully installed efficientnet-1.0.0 image-classifiers-1.0.0 keras-applications-1.0.8 segmentation-models-1.0.1\n",
            "Segmentation Models: using `keras` framework.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "scaler = MinMaxScaler()\n",
        "\n",
        "root_directory = 'drive/MyDrive/ColabNotebooks/Semantic segmentation dataset/'\n",
        "\n",
        "patch_size = 256\n",
        "\n",
        "# Read images into patches and crop\n",
        "image_dataset = []  \n",
        "for path, subdirs, files in os.walk(root_directory):\n",
        "    subdirs.sort(); # sort the subdirectory so the images and masks match\n",
        "    dirname = path.split(os.path.sep)[-1]\n",
        "    if dirname == 'images':   \n",
        "        images = os.listdir(path)  # list of all image names in this subdirectory\n",
        "        images.sort() # sort the images so they match with the masks\n",
        "        for i, image_name in enumerate(images):  \n",
        "            if image_name.endswith(\".jpg\"):              \n",
        "                image = cv2.imread(path+\"/\"+image_name, 1)  \n",
        "\n",
        "                # get the highest size divisble than 256 but less than the original size\n",
        "                SIZE_X = (image.shape[1]//patch_size)*patch_size \n",
        "                SIZE_Y = (image.shape[0]//patch_size)*patch_size \n",
        "\n",
        "                image = Image.fromarray(image)\n",
        "                image = image.crop((0 ,0, SIZE_X, SIZE_Y))  # crop from top left corner\n",
        "                image = np.array(image)             \n",
        "      \n",
        "                # extract patches from each image\n",
        "                print(\"Now patchifying image:\", path+\"/\"+image_name)\n",
        "                patches_img = patchify(image, (patch_size, patch_size, 3), step=patch_size)\n",
        "        \n",
        "                for i in range(patches_img.shape[0]):\n",
        "                    for j in range(patches_img.shape[1]):\n",
        "                        single_patch_img = patches_img[i,j,:,:]\n",
        "                        single_patch_img = scaler.fit_transform(single_patch_img.reshape(-1, single_patch_img.shape[-1])).reshape(single_patch_img.shape)\n",
        "                        single_patch_img = single_patch_img[0] # drop the extra unecessary dimension that patchify adds                         \n",
        "                        image_dataset.append(single_patch_img)\n",
        "                \n",
        "# Read corresponding masks into patches and crop\n",
        "mask_dataset = []  \n",
        "for path, subdirs, files in os.walk(root_directory):\n",
        "    subdirs.sort();\n",
        "    dirname = path.split(os.path.sep)[-1]\n",
        "    if dirname == 'masks':   \n",
        "        masks = os.listdir(path)  # list of all mask names in this subdirectory\n",
        "        masks.sort(); # sort the masks so they match with the images\n",
        "        for i, mask_name in enumerate(masks):  \n",
        "            if mask_name.endswith(\".png\"):     \n",
        "                mask = cv2.imread(path+\"/\"+mask_name, 1)  \n",
        "                mask = cv2.cvtColor(mask,cv2.COLOR_BGR2RGB)\n",
        "\n",
        "                # get the highest size divisble than 256 but less than the original size\n",
        "                SIZE_X = (mask.shape[1]//patch_size)*patch_size \n",
        "                SIZE_Y = (mask.shape[0]//patch_size)*patch_size \n",
        "\n",
        "                mask = Image.fromarray(mask)\n",
        "                mask = mask.crop((0 ,0, SIZE_X, SIZE_Y))  #Crop from top left corner\n",
        "                mask = np.array(mask)             \n",
        "      \n",
        "                # extract patches from each image\n",
        "                print(\"Now patchifying mask:\", path+\"/\"+mask_name)\n",
        "                patches_mask = patchify(mask, (patch_size, patch_size, 3), step=patch_size) \n",
        "        \n",
        "                for i in range(patches_mask.shape[0]):\n",
        "                    for j in range(patches_mask.shape[1]):\n",
        "                        \n",
        "                        single_patch_mask = patches_mask[i,j,:,:]\n",
        "                        single_patch_mask = single_patch_mask[0] # drop the extra unecessary dimension that patchify adds                             \n",
        "                        mask_dataset.append(single_patch_mask) \n",
        "\n",
        "image_dataset = np.array(image_dataset)\n",
        "mask_dataset =  np.array(mask_dataset)\n",
        "\n",
        "# Convert HEX to RGB array\n",
        "Building = '#3C1098'.lstrip('#')\n",
        "Building = np.array(tuple(int(Building[i:i+2], 16) for i in (0, 2, 4))) # 60, 16, 152\n",
        "\n",
        "Land = '#8429F6'.lstrip('#')\n",
        "Land = np.array(tuple(int(Land[i:i+2], 16) for i in (0, 2, 4))) #132, 41, 246\n",
        "\n",
        "Road = '#6EC1E4'.lstrip('#') \n",
        "Road = np.array(tuple(int(Road[i:i+2], 16) for i in (0, 2, 4))) #110, 193, 228\n",
        "\n",
        "Vegetation =  'FEDD3A'.lstrip('#') \n",
        "Vegetation = np.array(tuple(int(Vegetation[i:i+2], 16) for i in (0, 2, 4))) #254, 221, 58\n",
        "\n",
        "Water = 'E2A929'.lstrip('#') \n",
        "Water = np.array(tuple(int(Water[i:i+2], 16) for i in (0, 2, 4))) #226, 169, 41\n",
        "\n",
        "Unlabeled = '#9B9B9B'.lstrip('#') \n",
        "Unlabeled = np.array(tuple(int(Unlabeled[i:i+2], 16) for i in (0, 2, 4))) #155, 155, 155\n",
        "\n",
        "label = single_patch_mask\n",
        "\n",
        "# Converts an RGB value to an integer label\n",
        "def rgb_to_2D_label(label):\n",
        "    \"\"\"\n",
        "    Suply our labale masks as input in RGB format. \n",
        "    Replace pixels with specific RGB values ...\n",
        "    \"\"\"\n",
        "    label_seg = np.zeros(label.shape,dtype=np.uint8)\n",
        "    label_seg [np.all(label == Building,axis=-1)] = 0\n",
        "    label_seg [np.all(label==Land,axis=-1)] = 1\n",
        "    label_seg [np.all(label==Road,axis=-1)] = 2\n",
        "    label_seg [np.all(label==Vegetation,axis=-1)] = 3\n",
        "    label_seg [np.all(label==Water,axis=-1)] = 4\n",
        "    label_seg [np.all(label==Unlabeled,axis=-1)] = 5\n",
        "    \n",
        "    label_seg = label_seg[:,:,0]  #Just take the first channel, no need for all 3 channels\n",
        "    \n",
        "    return label_seg\n",
        "\n",
        "labels = []\n",
        "for i in range(mask_dataset.shape[0]):\n",
        "    label = rgb_to_2D_label(mask_dataset[i])\n",
        "    labels.append(label)    \n",
        "\n",
        "labels = np.array(labels)   \n",
        "labels = np.expand_dims(labels, axis=3)\n",
        "\n",
        "# Get categorical labels\n",
        "n_classes = len(np.unique(labels))\n",
        "from keras.utils import to_categorical\n",
        "labels_cat = to_categorical(labels, num_classes=n_classes)\n",
        "\n",
        "# Split the data\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(image_dataset, labels_cat, test_size = 0.20, random_state = 42)\n",
        "IMG_HEIGHT = X_train.shape[1]\n",
        "IMG_WIDTH  = X_train.shape[2]\n",
        "IMG_CHANNELS = X_train.shape[3]\n",
        "\n",
        "weights = [0.1666, 0.1666, 0.1666, 0.1666, 0.1666, 0.1666] # 1/6 = 0.1666\n",
        "dice_loss = sm.losses.DiceLoss(class_weights=weights) \n",
        "focal_loss = sm.losses.CategoricalFocalLoss()\n",
        "total_loss = dice_loss + (1 * focal_loss) # loss function is sum of dice loss and focal loss  \n",
        "\n",
        "metrics = []\n",
        "\n",
        "def get_model():\n",
        "    return multi_unet_model(n_classes=n_classes, IMG_HEIGHT=IMG_HEIGHT, IMG_WIDTH=IMG_WIDTH, IMG_CHANNELS=IMG_CHANNELS)\n",
        "\n",
        "model = get_model()\n",
        "model.compile(optimizer='adam', loss=total_loss, metrics=metrics)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JachHsqMl8JG",
        "outputId": "d9297c8e-e2e8-4c78-f86f-0961e1305185"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Now patchifying image: drive/MyDrive/ColabNotebooks/Semantic segmentation dataset/Tile 1/images/image_part_001.jpg\n",
            "Now patchifying image: drive/MyDrive/ColabNotebooks/Semantic segmentation dataset/Tile 1/images/image_part_002.jpg\n",
            "Now patchifying image: drive/MyDrive/ColabNotebooks/Semantic segmentation dataset/Tile 1/images/image_part_003.jpg\n",
            "Now patchifying image: drive/MyDrive/ColabNotebooks/Semantic segmentation dataset/Tile 1/images/image_part_004.jpg\n",
            "Now patchifying image: drive/MyDrive/ColabNotebooks/Semantic segmentation dataset/Tile 1/images/image_part_005.jpg\n",
            "Now patchifying image: drive/MyDrive/ColabNotebooks/Semantic segmentation dataset/Tile 1/images/image_part_006.jpg\n",
            "Now patchifying image: drive/MyDrive/ColabNotebooks/Semantic segmentation dataset/Tile 1/images/image_part_007.jpg\n",
            "Now patchifying image: drive/MyDrive/ColabNotebooks/Semantic segmentation dataset/Tile 1/images/image_part_008.jpg\n",
            "Now patchifying image: drive/MyDrive/ColabNotebooks/Semantic segmentation dataset/Tile 1/images/image_part_009.jpg\n",
            "Now patchifying image: drive/MyDrive/ColabNotebooks/Semantic segmentation dataset/Tile 2/images/image_part_001.jpg\n",
            "Now patchifying image: drive/MyDrive/ColabNotebooks/Semantic segmentation dataset/Tile 2/images/image_part_002.jpg\n",
            "Now patchifying image: drive/MyDrive/ColabNotebooks/Semantic segmentation dataset/Tile 2/images/image_part_003.jpg\n",
            "Now patchifying image: drive/MyDrive/ColabNotebooks/Semantic segmentation dataset/Tile 2/images/image_part_004.jpg\n",
            "Now patchifying image: drive/MyDrive/ColabNotebooks/Semantic segmentation dataset/Tile 2/images/image_part_005.jpg\n",
            "Now patchifying image: drive/MyDrive/ColabNotebooks/Semantic segmentation dataset/Tile 2/images/image_part_006.jpg\n",
            "Now patchifying image: drive/MyDrive/ColabNotebooks/Semantic segmentation dataset/Tile 2/images/image_part_007.jpg\n",
            "Now patchifying image: drive/MyDrive/ColabNotebooks/Semantic segmentation dataset/Tile 2/images/image_part_008.jpg\n",
            "Now patchifying image: drive/MyDrive/ColabNotebooks/Semantic segmentation dataset/Tile 2/images/image_part_009.jpg\n",
            "Now patchifying image: drive/MyDrive/ColabNotebooks/Semantic segmentation dataset/Tile 3/images/image_part_001.jpg\n",
            "Now patchifying image: drive/MyDrive/ColabNotebooks/Semantic segmentation dataset/Tile 3/images/image_part_002.jpg\n",
            "Now patchifying image: drive/MyDrive/ColabNotebooks/Semantic segmentation dataset/Tile 3/images/image_part_003.jpg\n",
            "Now patchifying image: drive/MyDrive/ColabNotebooks/Semantic segmentation dataset/Tile 3/images/image_part_004.jpg\n",
            "Now patchifying image: drive/MyDrive/ColabNotebooks/Semantic segmentation dataset/Tile 3/images/image_part_005.jpg\n",
            "Now patchifying image: drive/MyDrive/ColabNotebooks/Semantic segmentation dataset/Tile 3/images/image_part_006.jpg\n",
            "Now patchifying image: drive/MyDrive/ColabNotebooks/Semantic segmentation dataset/Tile 3/images/image_part_007.jpg\n",
            "Now patchifying image: drive/MyDrive/ColabNotebooks/Semantic segmentation dataset/Tile 3/images/image_part_008.jpg\n",
            "Now patchifying image: drive/MyDrive/ColabNotebooks/Semantic segmentation dataset/Tile 3/images/image_part_009.jpg\n",
            "Now patchifying image: drive/MyDrive/ColabNotebooks/Semantic segmentation dataset/Tile 4/images/image_part_001.jpg\n",
            "Now patchifying image: drive/MyDrive/ColabNotebooks/Semantic segmentation dataset/Tile 4/images/image_part_002.jpg\n",
            "Now patchifying image: drive/MyDrive/ColabNotebooks/Semantic segmentation dataset/Tile 4/images/image_part_003.jpg\n",
            "Now patchifying image: drive/MyDrive/ColabNotebooks/Semantic segmentation dataset/Tile 4/images/image_part_004.jpg\n",
            "Now patchifying image: drive/MyDrive/ColabNotebooks/Semantic segmentation dataset/Tile 4/images/image_part_005.jpg\n",
            "Now patchifying image: drive/MyDrive/ColabNotebooks/Semantic segmentation dataset/Tile 4/images/image_part_006.jpg\n",
            "Now patchifying image: drive/MyDrive/ColabNotebooks/Semantic segmentation dataset/Tile 4/images/image_part_007.jpg\n",
            "Now patchifying image: drive/MyDrive/ColabNotebooks/Semantic segmentation dataset/Tile 4/images/image_part_008.jpg\n",
            "Now patchifying image: drive/MyDrive/ColabNotebooks/Semantic segmentation dataset/Tile 4/images/image_part_009.jpg\n",
            "Now patchifying image: drive/MyDrive/ColabNotebooks/Semantic segmentation dataset/Tile 5/images/image_part_001.jpg\n",
            "Now patchifying image: drive/MyDrive/ColabNotebooks/Semantic segmentation dataset/Tile 5/images/image_part_002.jpg\n",
            "Now patchifying image: drive/MyDrive/ColabNotebooks/Semantic segmentation dataset/Tile 5/images/image_part_003.jpg\n",
            "Now patchifying image: drive/MyDrive/ColabNotebooks/Semantic segmentation dataset/Tile 5/images/image_part_004.jpg\n",
            "Now patchifying image: drive/MyDrive/ColabNotebooks/Semantic segmentation dataset/Tile 5/images/image_part_005.jpg\n",
            "Now patchifying image: drive/MyDrive/ColabNotebooks/Semantic segmentation dataset/Tile 5/images/image_part_006.jpg\n",
            "Now patchifying image: drive/MyDrive/ColabNotebooks/Semantic segmentation dataset/Tile 5/images/image_part_007.jpg\n",
            "Now patchifying image: drive/MyDrive/ColabNotebooks/Semantic segmentation dataset/Tile 5/images/image_part_008.jpg\n",
            "Now patchifying image: drive/MyDrive/ColabNotebooks/Semantic segmentation dataset/Tile 5/images/image_part_009.jpg\n",
            "Now patchifying image: drive/MyDrive/ColabNotebooks/Semantic segmentation dataset/Tile 6/images/image_part_001.jpg\n",
            "Now patchifying image: drive/MyDrive/ColabNotebooks/Semantic segmentation dataset/Tile 6/images/image_part_002.jpg\n",
            "Now patchifying image: drive/MyDrive/ColabNotebooks/Semantic segmentation dataset/Tile 6/images/image_part_003.jpg\n",
            "Now patchifying image: drive/MyDrive/ColabNotebooks/Semantic segmentation dataset/Tile 6/images/image_part_004.jpg\n",
            "Now patchifying image: drive/MyDrive/ColabNotebooks/Semantic segmentation dataset/Tile 6/images/image_part_005.jpg\n",
            "Now patchifying image: drive/MyDrive/ColabNotebooks/Semantic segmentation dataset/Tile 6/images/image_part_006.jpg\n",
            "Now patchifying image: drive/MyDrive/ColabNotebooks/Semantic segmentation dataset/Tile 6/images/image_part_007.jpg\n",
            "Now patchifying image: drive/MyDrive/ColabNotebooks/Semantic segmentation dataset/Tile 6/images/image_part_008.jpg\n",
            "Now patchifying image: drive/MyDrive/ColabNotebooks/Semantic segmentation dataset/Tile 6/images/image_part_009.jpg\n",
            "Now patchifying image: drive/MyDrive/ColabNotebooks/Semantic segmentation dataset/Tile 7/images/image_part_001.jpg\n",
            "Now patchifying image: drive/MyDrive/ColabNotebooks/Semantic segmentation dataset/Tile 7/images/image_part_002.jpg\n",
            "Now patchifying image: drive/MyDrive/ColabNotebooks/Semantic segmentation dataset/Tile 7/images/image_part_003.jpg\n",
            "Now patchifying image: drive/MyDrive/ColabNotebooks/Semantic segmentation dataset/Tile 7/images/image_part_004.jpg\n",
            "Now patchifying image: drive/MyDrive/ColabNotebooks/Semantic segmentation dataset/Tile 7/images/image_part_005.jpg\n",
            "Now patchifying image: drive/MyDrive/ColabNotebooks/Semantic segmentation dataset/Tile 7/images/image_part_006.jpg\n",
            "Now patchifying image: drive/MyDrive/ColabNotebooks/Semantic segmentation dataset/Tile 7/images/image_part_007.jpg\n",
            "Now patchifying image: drive/MyDrive/ColabNotebooks/Semantic segmentation dataset/Tile 7/images/image_part_008.jpg\n",
            "Now patchifying image: drive/MyDrive/ColabNotebooks/Semantic segmentation dataset/Tile 7/images/image_part_009.jpg\n",
            "Now patchifying image: drive/MyDrive/ColabNotebooks/Semantic segmentation dataset/Tile 8/images/image_part_001.jpg\n",
            "Now patchifying image: drive/MyDrive/ColabNotebooks/Semantic segmentation dataset/Tile 8/images/image_part_002.jpg\n",
            "Now patchifying image: drive/MyDrive/ColabNotebooks/Semantic segmentation dataset/Tile 8/images/image_part_003.jpg\n",
            "Now patchifying image: drive/MyDrive/ColabNotebooks/Semantic segmentation dataset/Tile 8/images/image_part_004.jpg\n",
            "Now patchifying image: drive/MyDrive/ColabNotebooks/Semantic segmentation dataset/Tile 8/images/image_part_005.jpg\n",
            "Now patchifying image: drive/MyDrive/ColabNotebooks/Semantic segmentation dataset/Tile 8/images/image_part_006.jpg\n",
            "Now patchifying image: drive/MyDrive/ColabNotebooks/Semantic segmentation dataset/Tile 8/images/image_part_007.jpg\n",
            "Now patchifying image: drive/MyDrive/ColabNotebooks/Semantic segmentation dataset/Tile 8/images/image_part_008.jpg\n",
            "Now patchifying image: drive/MyDrive/ColabNotebooks/Semantic segmentation dataset/Tile 8/images/image_part_009.jpg\n",
            "Now patchifying mask: drive/MyDrive/ColabNotebooks/Semantic segmentation dataset/Tile 1/masks/image_part_001.png\n",
            "Now patchifying mask: drive/MyDrive/ColabNotebooks/Semantic segmentation dataset/Tile 1/masks/image_part_002.png\n",
            "Now patchifying mask: drive/MyDrive/ColabNotebooks/Semantic segmentation dataset/Tile 1/masks/image_part_003.png\n",
            "Now patchifying mask: drive/MyDrive/ColabNotebooks/Semantic segmentation dataset/Tile 1/masks/image_part_004.png\n",
            "Now patchifying mask: drive/MyDrive/ColabNotebooks/Semantic segmentation dataset/Tile 1/masks/image_part_005.png\n",
            "Now patchifying mask: drive/MyDrive/ColabNotebooks/Semantic segmentation dataset/Tile 1/masks/image_part_006.png\n",
            "Now patchifying mask: drive/MyDrive/ColabNotebooks/Semantic segmentation dataset/Tile 1/masks/image_part_007.png\n",
            "Now patchifying mask: drive/MyDrive/ColabNotebooks/Semantic segmentation dataset/Tile 1/masks/image_part_008.png\n",
            "Now patchifying mask: drive/MyDrive/ColabNotebooks/Semantic segmentation dataset/Tile 1/masks/image_part_009.png\n",
            "Now patchifying mask: drive/MyDrive/ColabNotebooks/Semantic segmentation dataset/Tile 2/masks/image_part_001.png\n",
            "Now patchifying mask: drive/MyDrive/ColabNotebooks/Semantic segmentation dataset/Tile 2/masks/image_part_002.png\n",
            "Now patchifying mask: drive/MyDrive/ColabNotebooks/Semantic segmentation dataset/Tile 2/masks/image_part_003.png\n",
            "Now patchifying mask: drive/MyDrive/ColabNotebooks/Semantic segmentation dataset/Tile 2/masks/image_part_004.png\n",
            "Now patchifying mask: drive/MyDrive/ColabNotebooks/Semantic segmentation dataset/Tile 2/masks/image_part_005.png\n",
            "Now patchifying mask: drive/MyDrive/ColabNotebooks/Semantic segmentation dataset/Tile 2/masks/image_part_006.png\n",
            "Now patchifying mask: drive/MyDrive/ColabNotebooks/Semantic segmentation dataset/Tile 2/masks/image_part_007.png\n",
            "Now patchifying mask: drive/MyDrive/ColabNotebooks/Semantic segmentation dataset/Tile 2/masks/image_part_008.png\n",
            "Now patchifying mask: drive/MyDrive/ColabNotebooks/Semantic segmentation dataset/Tile 2/masks/image_part_009.png\n",
            "Now patchifying mask: drive/MyDrive/ColabNotebooks/Semantic segmentation dataset/Tile 3/masks/image_part_001.png\n",
            "Now patchifying mask: drive/MyDrive/ColabNotebooks/Semantic segmentation dataset/Tile 3/masks/image_part_002.png\n",
            "Now patchifying mask: drive/MyDrive/ColabNotebooks/Semantic segmentation dataset/Tile 3/masks/image_part_003.png\n",
            "Now patchifying mask: drive/MyDrive/ColabNotebooks/Semantic segmentation dataset/Tile 3/masks/image_part_004.png\n",
            "Now patchifying mask: drive/MyDrive/ColabNotebooks/Semantic segmentation dataset/Tile 3/masks/image_part_005.png\n",
            "Now patchifying mask: drive/MyDrive/ColabNotebooks/Semantic segmentation dataset/Tile 3/masks/image_part_006.png\n",
            "Now patchifying mask: drive/MyDrive/ColabNotebooks/Semantic segmentation dataset/Tile 3/masks/image_part_007.png\n",
            "Now patchifying mask: drive/MyDrive/ColabNotebooks/Semantic segmentation dataset/Tile 3/masks/image_part_008.png\n",
            "Now patchifying mask: drive/MyDrive/ColabNotebooks/Semantic segmentation dataset/Tile 3/masks/image_part_009.png\n",
            "Now patchifying mask: drive/MyDrive/ColabNotebooks/Semantic segmentation dataset/Tile 4/masks/image_part_001.png\n",
            "Now patchifying mask: drive/MyDrive/ColabNotebooks/Semantic segmentation dataset/Tile 4/masks/image_part_002.png\n",
            "Now patchifying mask: drive/MyDrive/ColabNotebooks/Semantic segmentation dataset/Tile 4/masks/image_part_003.png\n",
            "Now patchifying mask: drive/MyDrive/ColabNotebooks/Semantic segmentation dataset/Tile 4/masks/image_part_004.png\n",
            "Now patchifying mask: drive/MyDrive/ColabNotebooks/Semantic segmentation dataset/Tile 4/masks/image_part_005.png\n",
            "Now patchifying mask: drive/MyDrive/ColabNotebooks/Semantic segmentation dataset/Tile 4/masks/image_part_006.png\n",
            "Now patchifying mask: drive/MyDrive/ColabNotebooks/Semantic segmentation dataset/Tile 4/masks/image_part_007.png\n",
            "Now patchifying mask: drive/MyDrive/ColabNotebooks/Semantic segmentation dataset/Tile 4/masks/image_part_008.png\n",
            "Now patchifying mask: drive/MyDrive/ColabNotebooks/Semantic segmentation dataset/Tile 4/masks/image_part_009.png\n",
            "Now patchifying mask: drive/MyDrive/ColabNotebooks/Semantic segmentation dataset/Tile 5/masks/image_part_001.png\n",
            "Now patchifying mask: drive/MyDrive/ColabNotebooks/Semantic segmentation dataset/Tile 5/masks/image_part_002.png\n",
            "Now patchifying mask: drive/MyDrive/ColabNotebooks/Semantic segmentation dataset/Tile 5/masks/image_part_003.png\n",
            "Now patchifying mask: drive/MyDrive/ColabNotebooks/Semantic segmentation dataset/Tile 5/masks/image_part_004.png\n",
            "Now patchifying mask: drive/MyDrive/ColabNotebooks/Semantic segmentation dataset/Tile 5/masks/image_part_005.png\n",
            "Now patchifying mask: drive/MyDrive/ColabNotebooks/Semantic segmentation dataset/Tile 5/masks/image_part_006.png\n",
            "Now patchifying mask: drive/MyDrive/ColabNotebooks/Semantic segmentation dataset/Tile 5/masks/image_part_007.png\n",
            "Now patchifying mask: drive/MyDrive/ColabNotebooks/Semantic segmentation dataset/Tile 5/masks/image_part_008.png\n",
            "Now patchifying mask: drive/MyDrive/ColabNotebooks/Semantic segmentation dataset/Tile 5/masks/image_part_009.png\n",
            "Now patchifying mask: drive/MyDrive/ColabNotebooks/Semantic segmentation dataset/Tile 6/masks/image_part_001.png\n",
            "Now patchifying mask: drive/MyDrive/ColabNotebooks/Semantic segmentation dataset/Tile 6/masks/image_part_002.png\n",
            "Now patchifying mask: drive/MyDrive/ColabNotebooks/Semantic segmentation dataset/Tile 6/masks/image_part_003.png\n",
            "Now patchifying mask: drive/MyDrive/ColabNotebooks/Semantic segmentation dataset/Tile 6/masks/image_part_004.png\n",
            "Now patchifying mask: drive/MyDrive/ColabNotebooks/Semantic segmentation dataset/Tile 6/masks/image_part_005.png\n",
            "Now patchifying mask: drive/MyDrive/ColabNotebooks/Semantic segmentation dataset/Tile 6/masks/image_part_006.png\n",
            "Now patchifying mask: drive/MyDrive/ColabNotebooks/Semantic segmentation dataset/Tile 6/masks/image_part_007.png\n",
            "Now patchifying mask: drive/MyDrive/ColabNotebooks/Semantic segmentation dataset/Tile 6/masks/image_part_008.png\n",
            "Now patchifying mask: drive/MyDrive/ColabNotebooks/Semantic segmentation dataset/Tile 6/masks/image_part_009.png\n",
            "Now patchifying mask: drive/MyDrive/ColabNotebooks/Semantic segmentation dataset/Tile 7/masks/image_part_001.png\n",
            "Now patchifying mask: drive/MyDrive/ColabNotebooks/Semantic segmentation dataset/Tile 7/masks/image_part_002.png\n",
            "Now patchifying mask: drive/MyDrive/ColabNotebooks/Semantic segmentation dataset/Tile 7/masks/image_part_003.png\n",
            "Now patchifying mask: drive/MyDrive/ColabNotebooks/Semantic segmentation dataset/Tile 7/masks/image_part_004.png\n",
            "Now patchifying mask: drive/MyDrive/ColabNotebooks/Semantic segmentation dataset/Tile 7/masks/image_part_005.png\n",
            "Now patchifying mask: drive/MyDrive/ColabNotebooks/Semantic segmentation dataset/Tile 7/masks/image_part_006.png\n",
            "Now patchifying mask: drive/MyDrive/ColabNotebooks/Semantic segmentation dataset/Tile 7/masks/image_part_007.png\n",
            "Now patchifying mask: drive/MyDrive/ColabNotebooks/Semantic segmentation dataset/Tile 7/masks/image_part_008.png\n",
            "Now patchifying mask: drive/MyDrive/ColabNotebooks/Semantic segmentation dataset/Tile 7/masks/image_part_009.png\n",
            "Now patchifying mask: drive/MyDrive/ColabNotebooks/Semantic segmentation dataset/Tile 8/masks/image_part_001.png\n",
            "Now patchifying mask: drive/MyDrive/ColabNotebooks/Semantic segmentation dataset/Tile 8/masks/image_part_002.png\n",
            "Now patchifying mask: drive/MyDrive/ColabNotebooks/Semantic segmentation dataset/Tile 8/masks/image_part_003.png\n",
            "Now patchifying mask: drive/MyDrive/ColabNotebooks/Semantic segmentation dataset/Tile 8/masks/image_part_004.png\n",
            "Now patchifying mask: drive/MyDrive/ColabNotebooks/Semantic segmentation dataset/Tile 8/masks/image_part_005.png\n",
            "Now patchifying mask: drive/MyDrive/ColabNotebooks/Semantic segmentation dataset/Tile 8/masks/image_part_006.png\n",
            "Now patchifying mask: drive/MyDrive/ColabNotebooks/Semantic segmentation dataset/Tile 8/masks/image_part_007.png\n",
            "Now patchifying mask: drive/MyDrive/ColabNotebooks/Semantic segmentation dataset/Tile 8/masks/image_part_008.png\n",
            "Now patchifying mask: drive/MyDrive/ColabNotebooks/Semantic segmentation dataset/Tile 8/masks/image_part_009.png\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class MyWorker(Worker):\n",
        "\n",
        "    def __init__(self, *args, sleep_interval=0, **kwargs):\n",
        "      super().__init__(*args, **kwargs)\n",
        "\n",
        "    def compute(self, config, budget, **kwargs):\n",
        "        history = model.fit(X_train, y_train, \n",
        "                    batch_size = config['batchsize'], \n",
        "                    validation_batch_size = config['valbatchsize'], \n",
        "                    verbose=1, \n",
        "                    epochs=1, \n",
        "                    validation_data=(X_test, y_test), \n",
        "                    shuffle=False)\n",
        "        \n",
        "        lossarr = history.history['val_loss']\n",
        "        loss = lossarr[-1]\n",
        "\n",
        "        return({\n",
        "                    'loss': float(loss), \n",
        "                    'info': {} \n",
        "                })\n",
        "    \n",
        "    @staticmethod\n",
        "    def get_configspace():\n",
        "        config_space = CS.ConfigurationSpace()\n",
        "        config_space.add_hyperparameter(CS.UniformIntegerHyperparameter('batchsize', lower=1, upper=30))\n",
        "        config_space.add_hyperparameter(CS.UniformIntegerHyperparameter('valbatchsize', lower=1, upper=30))\n",
        "        return config_space\n",
        "\n"
      ],
      "metadata": {
        "id": "oy46vxXoEqQu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "NS = hpns.NameServer(run_id='example1', host='127.0.0.1', port=None)\n",
        "NS.start()\n",
        "w = MyWorker(sleep_interval = 0, nameserver='127.0.0.1',run_id='example1')\n",
        "w.run(background=True)\n",
        "bohb = BOHB(  configspace = w.get_configspace(),\n",
        "              run_id = 'example1', nameserver='127.0.0.1',\n",
        "              min_budget=20, max_budget=100\n",
        "           )\n",
        "bs_optimized = bohb.run(n_iterations=6)\n",
        "\n",
        "bohb.shutdown(shutdown_workers=True)\n",
        "NS.shutdown()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g12aa662Pszp",
        "outputId": "833ac734-54e9-4054-cc65-de687bebcc6b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "522/522 [==============================] - 212s 401ms/step - loss: 0.9832 - val_loss: 0.9471\n",
            "39/39 [==============================] - 202s 5s/step - loss: 0.9472 - val_loss: 0.9422\n",
            "70/70 [==============================] - 269s 4s/step - loss: 0.9459 - val_loss: 0.9431\n",
            "39/39 [==============================] - 263s 7s/step - loss: 0.9407 - val_loss: 0.9387\n",
            "42/42 [==============================] - 258s 6s/step - loss: 0.9365 - val_loss: 0.9321\n",
            "87/87 [==============================] - 268s 3s/step - loss: 0.9332 - val_loss: 0.9433\n",
            "174/174 [==============================] - 272s 2s/step - loss: 0.9360 - val_loss: 0.9285\n",
            "105/105 [==============================] - 267s 3s/step - loss: 0.9277 - val_loss: 0.9749\n",
            "44/44 [==============================] - 250s 6s/step - loss: 0.9211 - val_loss: 0.9248\n",
            "44/44 [==============================] - 254s 6s/step - loss: 0.9180 - val_loss: 0.9221\n",
            "53/53 [==============================] - 261s 5s/step - loss: 0.9169 - val_loss: 0.9261\n",
            "36/36 [==============================] - 253s 7s/step - loss: 0.9153 - val_loss: 0.9180\n",
            "46/46 [==============================] - 259s 6s/step - loss: 0.9144 - val_loss: 0.9418\n",
            "174/174 [==============================] - 267s 2s/step - loss: 0.9296 - val_loss: 0.9196\n",
            "36/36 [==============================] - 258s 7s/step - loss: 0.9172 - val_loss: 0.9197\n",
            "174/174 [==============================] - 270s 2s/step - loss: 0.9246 - val_loss: 0.9200\n",
            "522/522 [==============================] - 309s 591ms/step - loss: 0.9503 - val_loss: 0.9153\n",
            "522/522 [==============================] - 321s 615ms/step - loss: 0.9478 - val_loss: 0.9184\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "id2config = bs_optimized.get_id2config_mapping()\n",
        "incumbent = bs_optimized.get_incumbent_id()\n",
        "bs_optimized = id2config[incumbent]['config']['batchsize']\n",
        "vbs_optimized = id2config[incumbent]['config']['valbatchsize']\n",
        "print(f\"The optimized batch size is {bs_optimized}\")\n",
        "print(f\"The optimized validation batch size is {vbs_optimized}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gbJXJcBRnYlL",
        "outputId": "781b0a85-925b-40d5-91ef-382b3679b3fd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The optimized batch size is 2\n",
            "The optimized validation batch size is 29\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "mount_file_id": "1EjadDDnBXK_hT5uLqCRD-tR7Be740U2R",
      "authorship_tag": "ABX9TyORE0HwMtkTjDRqTU/uO7ry",
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}